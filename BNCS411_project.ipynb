{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "BNCS411_team7_term_project.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [
        "FlOF6NzB4r88",
        "Ptdsn82rrCdV",
        "gCRyzEm7n0M2"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "rm_IaJcCVnVv"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive',force_remount=True)\n",
        "#Create and mount on virtual gdrive through Colab"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i4onYOdnMGY5"
      },
      "source": [
        "#데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J8fq5hzZn2xb"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.layers import AveragePooling2D, Dropout, Flatten, Dense, Input\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from keras.models import Sequential\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from keras.callbacks import ReduceLROnPlateau\n",
        "from tensorflow.keras.preprocessing.image import img_to_array\n",
        "from tensorflow.keras.preprocessing.image import load_img\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import zipfile\n",
        "import io\n",
        "import glob\n",
        "from PIL import Image\n",
        "import dlib\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "from skimage.color import rgb2gray"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p3EJqYJTulvE"
      },
      "source": [
        "#Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FSXOGS3Y48sw"
      },
      "source": [
        "### Dataset load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O9V-MgDwvLkT"
      },
      "source": [
        "Downloaded files from github. Each of the zip files extracted on gdrive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooD-suyk_L1k"
      },
      "source": [
        "path_to_zip_file = '/gdrive/My Drive/BNCS411/mask_detection_report/with_mask.zip'\n",
        "directory_to_extract_to = '/gdrive/My Drive/BNCS411/mask_detection_report/ds/with_mask2'\n",
        "\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kfQ88kH4_MjT"
      },
      "source": [
        "path_to_zip_file = '/gdrive/My Drive/BNCS411/mask_detection_report/without_mask.zip'\n",
        "directory_to_extract_to = '/gdrive/My Drive/BNCS411/mask_detection_report/ds/without_mask2'\n",
        "\n",
        "with zipfile.ZipFile(path_to_zip_file, 'r') as zip_ref:\n",
        "    zip_ref.extractall(directory_to_extract_to)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "icOrpgjs5Oui"
      },
      "source": [
        "# Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7Fs_Hl_k5elw"
      },
      "source": [
        "###Localize face boundary"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WfR-bHH1vbg5"
      },
      "source": [
        "Import pretrained ssd model\r\n",
        "\r\n",
        "Define it as facenet, find each of the dataset's facial area"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xLKyJSx5dyrL"
      },
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "facenet = cv2.dnn.readNet('/gdrive/MyDrive/BNCS411/mask_detection_report/model/deploy.prototxt', \n",
        "                          '/gdrive/MyDrive/BNCS411/mask_detection_report/model/res10_300x300_ssd_iter_140000.caffemodel')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H-TCJSR25QLL"
      },
      "source": [
        "mask_faces = []\n",
        "for i in glob.glob('/gdrive/MyDrive/BNCS411/mask_detection_report/with_mask2/*.jpg'):\n",
        "    test = cv2.imread(i)\n",
        "    h, w = test.shape[:2]\n",
        "\n",
        "    #load_model('/gdrive/MyDrive/BNCS411/mask_detection_report/mask_detector.model')\n",
        "    blob = cv2.dnn.blobFromImage(test, 1.0, size=(150,150), mean=(104.0, 177.0, 123.0), crop = False)\n",
        "    facenet.setInput(blob)\n",
        "    dets = facenet.forward()\n",
        "\n",
        "    max = 0\n",
        "    argmax = 0\n",
        "    for j in range(dets.shape[2]):\n",
        "        confidence = dets[0, 0, j, 2]\n",
        "        if max < confidence:\n",
        "            max = confidence\n",
        "            argmax=j\n",
        "    \n",
        "    x1 = int(dets[0, 0, argmax, 3] * w)\n",
        "    y1 = int(dets[0, 0, argmax, 4] * h)\n",
        "    x2 = int(dets[0, 0, argmax, 5] * w)\n",
        "    y2 = int(dets[0, 0, argmax, 6] * h)\n",
        "    \n",
        "    face = test[y1:y2, x1:x2]\n",
        "    \n",
        "    if np.sum(face)==0:\n",
        "        continue\n",
        "    face = cv2.resize(face, (224,224))\n",
        "    mask_faces.append(face)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIS7MBLWudF3"
      },
      "source": [
        "unmask_faces = []\n",
        "for i in glob.glob('/gdrive/MyDrive/BNCS411/mask_detection_report/without_mask2/*.jpg'):\n",
        "    test = cv2.imread(i)\n",
        "    h, w = test.shape[:2]\n",
        "\n",
        "    #load_model('/gdrive/MyDrive/BNCS411/mask_detection_report/mask_detector.model')\n",
        "    blob = cv2.dnn.blobFromImage(test, 1.0, size=(150,150), mean=(104.0, 177.0, 123.0), crop = False)\n",
        "    facenet.setInput(blob)\n",
        "    dets = facenet.forward()\n",
        "\n",
        "    max = 0\n",
        "    argmax = 0\n",
        "    for j in range(dets.shape[2]):\n",
        "        confidence = dets[0, 0, j, 2]\n",
        "        if max < confidence:\n",
        "            max = confidence\n",
        "            argmax=j\n",
        "    \n",
        "    \n",
        "    x1 = int(dets[0, 0, argmax, 3] * w)\n",
        "    y1 = int(dets[0, 0, argmax, 4] * h)\n",
        "    x2 = int(dets[0, 0, argmax, 5] * w)\n",
        "    y2 = int(dets[0, 0, argmax, 6] * h)\n",
        "    \n",
        "    face = test[y1:y2, x1:x2]\n",
        "    \n",
        "    if np.sum(face)==0:\n",
        "        continue\n",
        "    face = cv2.resize(face, (224,224))\n",
        "    unmask_faces.append(face)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KBEtngnPu9pZ"
      },
      "source": [
        "len(mask_faces)\r\n",
        "len(unmask_faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JsyOom-6araK"
      },
      "source": [
        "plt.figure(figsize=(22, 22))\n",
        "for i, face in enumerate(unmask_faces):\n",
        "        plt.subplot(27, 27, i+1)\n",
        "        plt.imshow(face[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VBopg5ZivcGS"
      },
      "source": [
        "plt.figure(figsize=(22, 22))\n",
        "for i, face in enumerate(mask_faces):\n",
        "        plt.subplot(27, 27, i+1)\n",
        "        plt.imshow(face[:, :, ::-1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gpiA2CZzwr5N"
      },
      "source": [
        "Save detected image files"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CplufQSmwAKB"
      },
      "source": [
        "np.save('/gdrive/MyDrive/BNCS411/mask_detection_report/npds/unmask2.npy', unmask_faces)\r\n",
        "np.save('/gdrive/MyDrive/BNCS411/mask_detection_report/npds/mask2.npy', mask_faces)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M5fH15vD5lgJ"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P-QGfyy85_Cc"
      },
      "source": [
        "Load localized images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xahBJYcgrHR6"
      },
      "source": [
        "unmask = np.load('/gdrive/MyDrive/BNCS411/mask_detection_report/npds/unmask2.npy')\n",
        "mask = np.load('/gdrive/MyDrive/BNCS411/mask_detection_report/npds/mask2.npy')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qrLoozhx1gf7"
      },
      "source": [
        "m_lb = mask.shape[0]\r\n",
        "u_lb = unmask.shape[0]\r\n",
        "masklb = [0]*m_lb\r\n",
        "unmasklb = [1]*u_lb"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5A3fqZXFxHnL"
      },
      "source": [
        "ds = np.concatenate((mask, unmask), axis = 0)\r\n",
        "lb = np.concatenate((masklb, unmasklb))\r\n",
        "ds.shape, lb.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QecouVxm5plg"
      },
      "source": [
        "Important thing is before generating augmented dataset, split data into train and validation set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4bTXOk4yw6ks"
      },
      "source": [
        "Xtrain, Xtest, trainlb, Ytest = train_test_split(ds, lb, test_size=0.2, random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EY8X6nt00XPv"
      },
      "source": [
        "image_gen = ImageDataGenerator(rotation_range = 30,\n",
        "                               width_shift_range=0.1,\n",
        "                               height_shift_range=0.1,\n",
        "                               rescale = 1/255,\n",
        "                               shear_range=0.2,\n",
        "                               zoom_range=0.2,\n",
        "                               horizontal_flip=True,\n",
        "                               fill_mode='nearest')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dMhFlSkF6PQT"
      },
      "source": [
        "Check the generation working well"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l4fzt3s90yaJ"
      },
      "source": [
        "fig, axs = plt.subplots(5,5,figsize = (10,10))\n",
        "k=0\n",
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        axs[i][j].imshow(image_gen.random_transform(Xtrain[k]))\n",
        "        k+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tKJPHlou6hrH"
      },
      "source": [
        "Save as augmented data as 'aug_ds'"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HC1MzRav19PP"
      },
      "source": [
        "aug_ds = []\n",
        "for i in range(Xtrain.shape[0]):\n",
        "    tmp = image_gen.random_transform(Xtrain[i])\n",
        "    aug_ds.append(tmp)\n",
        "\n",
        "aug_ds = np.array(aug_ds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gFk7e3WHGx0Q"
      },
      "source": [
        "aug_ds.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dvHrgE4H7LK0"
      },
      "source": [
        "fullds = np.concatenate((Xtrain, aug_ds), axis = 0)\r\n",
        "Ytrain = np.concatenate((trainlb, trainlb))\r\n",
        "fullds.shape, Ytrain.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8fnlhYL64uF"
      },
      "source": [
        "### Normalizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ikXvJjw0HR6r"
      },
      "source": [
        "ds_gray = rgb2gray(fullds) #grayscale\n",
        "Xtest = rgb2gray(Xtest)\n",
        "ds_gray.shape, Xtest.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZTXYKEKQQQXj"
      },
      "source": [
        "blur_fullds = [] #denoise and smoothing\n",
        "blur_test = []\n",
        "for i in range(ds_gray.shape[0]):\n",
        "    blur = cv2.GaussianBlur(ds_gray[i, :,:], (5, 5), 0)\n",
        "    blur_fullds.append(blur)\n",
        "    \n",
        "for i in range(Xtest.shape[0]):\n",
        "    testblur = cv2.GaussianBlur(Xtest[i, :,:], (5, 5), 0)\n",
        "    blur_test.append(testblur)\n",
        "\n",
        "blur_fullds = np.array(blur_fullds, dtype=np.float32)\n",
        "blur_test = np.array(blur_test, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZO25suRdQHYe"
      },
      "source": [
        "#minmax scaling\n",
        "stdds = []\n",
        "Xtest = []\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "for i in range(blur_fullds.shape[0]):\n",
        "    scaler = MinMaxScaler()\n",
        "    stdds.append(scaler.fit_transform(blur_fullds[i,:,:]))\n",
        "\n",
        "for i in range(blur_test.shape[0]):\n",
        "    scaler = MinMaxScaler()\n",
        "    Xtest.append(scaler.fit_transform(blur_test[i,:,:]))\n",
        "\n",
        "stdds = np.array(stdds)\n",
        "stdts = np.array(Xtest)\n",
        "stdds.shape, stdts.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1cnuRwWkLAZ5"
      },
      "source": [
        "fig, axs = plt.subplots(5,5,figsize = (10,10))\n",
        "k=0\n",
        "for i in range(5):\n",
        "    for j in range(5):\n",
        "        axs[i][j].imshow(stdds[k])\n",
        "        k+=1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rzyYW2-kx4OZ"
      },
      "source": [
        "Xtrain = np.expand_dims(stdds, axis=-1)\n",
        "Xtest = np.expand_dims(stdts, axis=-1)\n",
        "Xtrain.shape, Ytrain.shape, Xtest.shape, Ytest.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e5ROYksR6sdP"
      },
      "source": [
        "# CNN model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pnaiwVq7zw03"
      },
      "source": [
        "model = Sequential([\n",
        "    keras.layers.Conv2D(input_shape=(224,224,1), filters=15, kernel_size=3, strides=1, padding='same'),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(2,2),\n",
        "    keras.layers.Conv2D(filters=20, kernel_size=3, strides=1, padding='same'),\n",
        "    keras.layers.Activation('relu'),\n",
        "    keras.layers.MaxPool2D(2,2),\n",
        "    keras.layers.Flatten(),\n",
        "    keras.layers.Dense(60, activation='relu'),\n",
        "    keras.layers.Dense(1, activation='sigmoid'),\n",
        "])\n",
        "\n",
        "model.compile(optimizer=Adam(learning_rate=0.00001), loss = 'binary_crossentropy', metrics=['accuracy'])\n",
        "\n",
        "checkpoint_cb = keras.callbacks.ModelCheckpoint(\n",
        "    \"/gdrive/MyDrive/BNCS411/mask_detection_report/my_modelaug.h5\", save_best_only=True\n",
        ")\n",
        "learning_rate_reduction = ReduceLROnPlateau(monitor='val_accuracy', patience=5, min_lr=0)\n",
        "early_stopping_cb = keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=10)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "89657-xVN1Ly"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TGRuLJhd4Vr_"
      },
      "source": [
        "from IPython.display import SVG\n",
        "from keras.utils.vis_utils import model_to_dot\n",
        "%matplotlib inline\n",
        "\n",
        "SVG(model_to_dot(model, show_shapes=True, dpi=60).create(prog='dot', format='svg', ))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X2otAzMJPAVd"
      },
      "source": [
        "history = model.fit(Xtrain, Ytrain, validation_data=(Xtest, Ytest), epochs=10, callbacks = [early_stopping_cb, learning_rate_reduction, checkpoint_cb])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJk1_HS_ibzS"
      },
      "source": [
        "plt.figure(figsize=(12,6))\n",
        "plt.subplot(2,1,1)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "\n",
        "plt.subplot(2,1,2)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Accuracy')\n",
        "plt.ylabel('accuracy')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZhyEPkjiWNJ"
      },
      "source": [
        "#Test"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FlOF6NzB4r88"
      },
      "source": [
        "###Test for images"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7FneUrPP4v24"
      },
      "source": [
        "weight_path = \"/gdrive/MyDrive/BNCS411/mask_detection_report/my_modelaug.h5\"\n",
        "\n",
        "model = tf.keras.models.load_model(weight_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C9QRg3ns5D6W"
      },
      "source": [
        "test = []\n",
        "for i in glob.glob('/gdrive/MyDrive/BNCS411/mask_detection_report/test/*.jpg'):\n",
        "    img = cv2.imread(i)\n",
        "    h, w = img.shape[:2]\n",
        "\n",
        "    #load_model('/gdrive/MyDrive/BNCS411/mask_detection_report/mask_detector.model')\n",
        "    blob = cv2.dnn.blobFromImage(img, 1.0, size=(150,150), mean=(104.0, 177.0, 123.0), crop = False)\n",
        "    facenet.setInput(blob)\n",
        "    dets = facenet.forward()\n",
        "\n",
        "    max = 0\n",
        "    argmax = 0\n",
        "    for j in range(dets.shape[2]):\n",
        "        confidence = dets[0, 0, j, 2]\n",
        "        if max < confidence:\n",
        "            max = confidence\n",
        "            argmax=j\n",
        "    \n",
        "    x1 = int(dets[0, 0, argmax, 3] * w)\n",
        "    y1 = int(dets[0, 0, argmax, 4] * h)\n",
        "    x2 = int(dets[0, 0, argmax, 5] * w)\n",
        "    y2 = int(dets[0, 0, argmax, 6] * h)\n",
        "    \n",
        "    face = img[y1:y2, x1:x2]\n",
        "    \n",
        "    if np.sum(face)==0:\n",
        "        continue\n",
        "    face = cv2.resize(face, (224,224))\n",
        "    test.append(face)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IdAUVFAV53j9"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "plt.imshow(test[6])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1jvvk1O6x69"
      },
      "source": [
        "test = np.array(test)\n",
        "test = rgb2gray(test)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3PxlB_a3ZKu"
      },
      "source": [
        "blur_testimg = []\r\n",
        "for i in range(test.shape[0]):\r\n",
        "    blur = cv2.GaussianBlur(test[i, :,:], (5, 5), 0)\r\n",
        "    blur_testimg.append(blur)\r\n",
        "\r\n",
        "blur_testimg = np.array(blur_testimg, dtype=np.float32)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sI8c9bX57Pu9"
      },
      "source": [
        "full = []\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "for i in range(blur_testimg.shape[0]):\n",
        "    scaler = StandardScaler()\n",
        "    full.append(scaler.fit_transform(blur_testimg[i,:,:]))\n",
        "\n",
        "fullts = np.array(test)\n",
        "fullts.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gZInWJ6w87zT"
      },
      "source": [
        "plt.figure(figsize=(10, 10))\n",
        "for i in range(7):\n",
        "    plt.subplot(3, 3, i+1)\n",
        "    plt.imshow(test[i, :, :])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cXbEJ7Cx7VQc"
      },
      "source": [
        "fullts = np.expand_dims(fullts, axis=-1)\n",
        "fullts.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5jel9EdU6dO_"
      },
      "source": [
        "model.predict(fullts)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SM_n0jz-4q50"
      },
      "source": [
        "###Test with webcam\r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lce6Gnfb4oTp"
      },
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\r\n",
        "scaler = MinMaxScaler()\r\n",
        "vid = open('/content/test.mp4')\r\n",
        "vid_in = cv2.VideoCapture('/content/test.mp4')\r\n",
        "\r\n",
        "while True:\r\n",
        "    ret, image = vid_in.read()\r\n",
        "    \r\n",
        "    h, w = image.shape[:2]\r\n",
        "    blob = cv2.dnn.blobFromImage(image, 1.0, size=(300,300), mean=(104.0, 177.0, 123.0), crop = False)\r\n",
        "    facenet.setInput(blob)\r\n",
        "    dets = facenet.forward()\r\n",
        "\r\n",
        "    faces = []\r\n",
        "\r\n",
        "    for j in range(dets.shape[2]):\r\n",
        "        confidence = dets[0, 0, j, 2]\r\n",
        "        if confidence < 0.5:\r\n",
        "            continue\r\n",
        "\r\n",
        "\r\n",
        "        x1 = int(dets[0, 0, j, 3] * w)\r\n",
        "        y1 = int(dets[0, 0, j, 4] * h)\r\n",
        "        x2 = int(dets[0, 0, j, 5] * w)\r\n",
        "        y2 = int(dets[0, 0, j, 6] * h)\r\n",
        "\r\n",
        "        face = image[y1:y2, x1:x2]\r\n",
        "        faces.append(face)\r\n",
        "\r\n",
        "        for i, face in enumerate(faces):\r\n",
        "            face_input = cv2.resize(face, (224,224))\r\n",
        "            face_input = cv2.cvtColor(face_input, cv2.COLOR_BGR2GRAY)\r\n",
        "            face_input = cv2.GaussianBlur(face_input, (5,5), 0)\r\n",
        "            face_input = scaler.fit_transform(face_input)\r\n",
        "            face_input = np.expand_dims(face_input, axis=0)\r\n",
        "            face_input = np.expand_dims(face_input, axis=3)\r\n",
        "\r\n",
        "            pred = model.predict_classes(face_input)\r\n",
        "\r\n",
        "            if pred[0][0] == 0:\r\n",
        "                cv2.rectangle(image, (x1, y1), (x2, y2), (255,0,0), 3)\r\n",
        "                cv2.putText(image, 'Mask On', (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\r\n",
        "\r\n",
        "            else:\r\n",
        "                cv2.rectangle(image, (x1, y1), (x2, y2), (0,0,255), 3)\r\n",
        "                cv2.putText(image, 'Mask Off', (x1,y1), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (255,255,255), 2)\r\n",
        "\r\n",
        "    \r\n",
        "    cv2_imshow(image)\r\n",
        "    \r\n",
        "    key = cv2.waitKey(1)\r\n",
        "    \r\n",
        "    if key == 27:\r\n",
        "        break\r\n",
        "\r\n",
        "vid_in.release()\r\n",
        "cv2.destroyAllWindows()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}